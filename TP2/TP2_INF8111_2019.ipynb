{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF8111 - Fouille de donn√©es\n",
    "\n",
    "\n",
    "## TP2 Automne 2019 - Extraction et analyse d'une base de donn√©es de tweets\n",
    "\n",
    "##### Membres de l'√©quipe:\n",
    "\n",
    "    - Nom (Matricule) 1\n",
    "    - Nom (Matricule) 2\n",
    "    - Nom (Matricule) 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©sentation du probl√®me\n",
    "\n",
    "En 2017, Twitter compte 313 millions d‚Äôutilisateurs actifs par mois avec 500 millions de tweets envoy√©s par jour. Cette information est rendue disponible √† destination de la recherche et du d√©veloppement web gr√¢ce √† une API publique qui permet de collecter les informations que l'on souhaite.\n",
    "\n",
    "N√©anmoins, la politique de d√©veloppement de Twitter limite le partage de ces donn√©es. En effet, le partage du contenu des tweets dans une base de donn√©es n'est pas autoris√©, seuls les identifiants des tweets le sont. \n",
    "Pour partager publiquement une base de donn√©es de tweets que l'on a cr√©√©e, il faut que cette base de donn√©es ne soit consitu√©e que des identifiants de tweets, et c'est ce que l'on retrouve dans la plupart des jeux de donn√©es publiques.\n",
    "\n",
    "Il est donc n√©cessaire pour exploiter ces donn√©es \"d'hydrater\" les tweets en question, c'est-√†-dire extraire l'ensemble des informations √† partir de l'ID, ce qui demande d'utiliser l'API de Twitter.\n",
    "\n",
    "Nous allons ici utiliser des bases de donn√©es publiques cr√©√©es par GWU (George Washington University), qui ont l'avantage d'√™tre tr√®s r√©centes : \n",
    "https://dataverse.harvard.edu/dataverse/gwu-libraries\n",
    "\n",
    "Chaque base de donn√©es de GWU couvre un sujet pr√©cis (√©lection am√©ricaine de 2016, jeux olympiques, etc.), et les donn√©es ont √©t√© recueillis en appliquant des requ√™tes qui filtraient les r√©sultats pour n'avoir que des tweets pertinents. Un fichier README est fourni avec chaque base de donn√©es pour donner les d√©tails de cr√©ation du *dataset*. \n",
    "\n",
    "\n",
    "**Les objectifs de ce TP sont donc les suivants :**\n",
    "\n",
    " 1. Construire un *crawler* qui collecte les informations d'un tweet √† partir de son ID, avec le jeu de donn√©es de son choix et les informations pertinentes pour le sujet choisi\n",
    " 2. A partir de ces donn√©es de Twitter collect√©s, application de m√©thodes en Machine Learning (ML)/Natural Language Processing (NLP) pour fournir une analyse pertinente. \n",
    "\n",
    "\n",
    "Twitter autorisant le partage **local** des donn√©es (par exemple au sein d'un groupe de recherche), une base de donn√©es sera fournie si vous ne parvenez pas √† cr√©er la v√¥tre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Hydratation de tweets √† l'aide de l'API Twitter (4 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtenir l'authorisation de Twitter pour l'utilisation de l'API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'authentification, Twitter utilise OAuth : https://developer.twitter.com/en/docs/basics/authentication/overview/oauth\n",
    "Vous aurez ici besoin en particulier de OAuth2, car vous n'allez pas interagir avec des utilisateurs sur Twitter (simplement collect√©s des donn√©es).\n",
    "\n",
    "##### 1.1. Obtention d'un compte Twitter d√©veloppeur\n",
    "\n",
    " La premi√®re √©tape n√©cessaire pour enregistrer votre application et de cr√©er un compte Twitter d√©veloppeur. Pour ce faire :\n",
    "\n",
    " - Cr√©ez un compte Twitter classique si vous n'en avez pas d√©j√† un.\n",
    " \n",
    " - Sur le site, https://developer.twitter.com, cliquez sur *apply* pour obtenir un compte d√©veloppeur. \n",
    " \n",
    " - Remplissez tous les champs n√©cessaires. Twitter demande beaucoup de d√©tails sur l'utilisation que vous allez faire de ce compte, il est donc important d'expliquer la d√©marche en d√©tail : il faut souligner le fait que le projet est **acad√©mique** (aucune intention commerciale, aucune publication des donn√©es collect√©s, etc.), expliquer les objectifs et l'apprentissage de ce TP (prise en main de l'API Twitter, l'application concr√®te de m√©thodes de Data Mining, etc.), mais aussi expliquer en d√©tail ce que vous allez faire des donn√©es (en reprenant des consignes du sujet), les m√©thodes que vous allez appliquer (citez des m√©thodes vues en cours ou au pr√©c√©dent TP), le rendu fourni (insistez sur le fait que rien ne sera publique), etc. Pensez notamment √† indiquer le nom du cours et le sigle du cours, le nom de l'√©tablissement, mon nom (Th√©o Moins), etc. Cochez que vous n'utiliserez pas la fonctionnalit√© de Retweet, et que l'aggregation et l'affichage de tweets ne sera fait que dans un cadre p√©dagogique (non publique, et sous la forme d'un projet de recherche). Si jamais vous n'√™tes pas assez pr√©cis, Twitter peut vous renvoyer un courriel pour vous demander des pr√©cisions. \n",
    "\n",
    "##### 1.2. Obtention d'un jeton d'acc√®s\n",
    "\n",
    " - Lorsque Twitter aura valid√© votre demande de compte d√©veloppeur, allez sur https://developer.twitter.com/en/apps pour cr√©er une application (cliquer sur *create an app*)\n",
    "\n",
    "- Ici encore, des informations sont √† fournir ici. Certaines, comme le nom ou le site internet, ne sont pas tr√®s importante, vous pouvez mettre un site internet factice si vous le souhaitez.\n",
    "\n",
    "- A la fin de ce processus, vous pouvez enfin obtenir les cl√©s et les jetons pour utiliser l'API: allez sur la page de l'application pour cr√©er les jetons. Vous devez r√©cup√©rer une paire de cl√©s et une paire de jetons pour passer √† la suite.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"cpPHmBT3T0dKZr9ZB0VcdyTEu\"\n",
    "CONSUMER_SECRET = \"sDxmDZ8oJG7bAqzvw64Mtm9Bg9OYFvrkwSaT6UkBrqWMIlKd3V\"\n",
    "\n",
    "oauth_token = \"1181291928219992064-8uCGp2G7U8AAUXs2CbNNJKRkNsH7FT\"\n",
    "oauth_secret = \"V73rd6JMas90l3Xe1ctHm64y3gjO92Q3IJiFQLGT1hSBQ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Premiers pas avec Twython\n",
    "\n",
    "##### 2.1 Installation et import de la librairie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs librairies Python existent pour manipuler l'API Twitter. Aussi appel√© *wrappers*, ce sont un ensemble de fonctions python qui appelle des fonctions de l'API. Parmi elles, nous utiliserons Twython, librairie r√©pendue et activement maintenue.\n",
    "\n",
    "Documentation de Twython : https://twython.readthedocs.io/en/latest/api.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from twython import Twython, TwythonError, TwythonRateLimitError\n",
    "except ImportError:\n",
    "    !pip install --user twython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Cr√©ation d'une application et premiers tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, oauth_token, oauth_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un test avec une recherche tr√®s simple pour vous assurer que la requ√™te fonctionne.\n",
    "\n",
    "La fonction search renvoie une recherche (non exhaustive) de tweets, et l'option \"*popular*\" permet de retourner les r√©sultats les plus populaires de la r√©ponse. (documentation ici: https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_search = twitter.search(q='python', result_type='popular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `search` renvoie un dictionnaire contenant la liste de tweets de la requ√™te, et les m√©tadonn√©es.\n",
    "\n",
    "Voici un exemple d'un r√©sultat d'une recherche, observez ainsi toutes les donn√©es/m√©tadonn√©es que contient un tweet et que vous pouvez extraire par la suite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sat Oct 19 11:20:00 +0000 2019',\n",
       " 'id': 1185515941335052288,\n",
       " 'id_str': '1185515941335052288',\n",
       " 'text': 'What‚Äôs New In Python 3.8?  Check out the new features in Python 3.8, compared to 3.7. https://t.co/rIbcmehcUN. For‚Ä¶ https://t.co/v62WAR7LNO',\n",
       " 'truncated': True,\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [],\n",
       "  'urls': [{'url': 'https://t.co/rIbcmehcUN',\n",
       "    'expanded_url': 'https://docs.python.org/3.8/whatsnew/3.8.html',\n",
       "    'display_url': 'docs.python.org/3.8/whatsnew/3‚Ä¶',\n",
       "    'indices': [86, 109]},\n",
       "   {'url': 'https://t.co/v62WAR7LNO',\n",
       "    'expanded_url': 'https://twitter.com/i/web/status/1185515941335052288',\n",
       "    'display_url': 'twitter.com/i/web/status/1‚Ä¶',\n",
       "    'indices': [116, 139]}]},\n",
       " 'metadata': {'result_type': 'popular', 'iso_language_code': 'en'},\n",
       " 'source': '<a href=\"https://sproutsocial.com\" rel=\"nofollow\">Sprout Social</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 63873759,\n",
       "  'id_str': '63873759',\n",
       "  'name': 'Python Software Foundation',\n",
       "  'screen_name': 'ThePSF',\n",
       "  'location': 'Everywhere Python is!',\n",
       "  'description': 'The Python Software Foundation. For help with Python code, see comp.lang.python.',\n",
       "  'url': 'http://t.co/KdOzhmst4U',\n",
       "  'entities': {'url': {'urls': [{'url': 'http://t.co/KdOzhmst4U',\n",
       "      'expanded_url': 'http://www.python.org/psf',\n",
       "      'display_url': 'python.org/psf',\n",
       "      'indices': [0, 22]}]},\n",
       "   'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 279743,\n",
       "  'friends_count': 107,\n",
       "  'listed_count': 4206,\n",
       "  'created_at': 'Sat Aug 08 01:26:03 +0000 2009',\n",
       "  'favourites_count': 191,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': False,\n",
       "  'verified': True,\n",
       "  'statuses_count': 4768,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': '2B9DD6',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/439154912719413248/pUBY5pVj_normal.png',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/439154912719413248/pUBY5pVj_normal.png',\n",
       "  'profile_link_color': '0084B4',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'FFEE30',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'has_extended_profile': False,\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': False,\n",
       "  'follow_request_sent': False,\n",
       "  'notifications': False,\n",
       "  'translator_type': 'none'},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 55,\n",
       " 'favorite_count': 132,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_search['statuses'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est √©galement possible avec Twython de r√©cup√©rer les informations d'un tweet √† partir de son ID. \n",
    "\n",
    "#### Question 1. Afficher la date, le nom d'utilisateur et le contenu du tweet ayant l'ID : 1157345692517634049 (0.5 Pts)\n",
    "\n",
    "*Indice : vous pourrez utiliser avec la fonction de twython `show_status`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': 'Fri Aug 02 17:41:30 +0000 2019', 'id': 1157345692517634049, 'id_str': '1157345692517634049', 'text': 'A$AP Rocky released from prison and on his way home to the United States from Sweden. It was a Rocky Week, get home ASAP A$AP!', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': []}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 25073877, 'id_str': '25073877', 'name': 'Donald J. Trump', 'screen_name': 'realDonaldTrump', 'location': 'Washington, DC', 'description': '45th President of the United States of Americaüá∫üá∏', 'url': 'https://t.co/OMxB0x7xC5', 'entities': {'url': {'urls': [{'url': 'https://t.co/OMxB0x7xC5', 'expanded_url': 'http://www.Instagram.com/realDonaldTrump', 'display_url': 'Instagram.com/realDonaldTrump', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 65991538, 'friends_count': 47, 'listed_count': 110091, 'created_at': 'Wed Mar 18 13:46:38 +0000 2009', 'favourites_count': 6, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': True, 'statuses_count': 45339, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': True, 'profile_background_color': '6D5C18', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': True, 'profile_image_url': 'http://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/25073877/1560920145', 'profile_link_color': '1B95E0', 'profile_sidebar_border_color': 'BDDCAD', 'profile_sidebar_fill_color': 'C5CEC0', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'regular'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 246896, 'favorite_count': 871736, 'favorited': False, 'retweeted': False, 'lang': 'en'}\n"
     ]
    }
   ],
   "source": [
    "test_id = \"1157345692517634049\"\n",
    "MyTweet = twitter.show_status(id=test_id)\n",
    "print(MyTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** : Twitter a une limitation de requ√™te par fen√™tre de 15 minutes, qui est donc √† prendre en compte dans la base de donn√©es : https://developer.twitter.com/en/docs/basics/rate-limiting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hydratation d'une base de donn√©e de tweets\n",
    "\n",
    "Les choses s√©rieuses commencent ! \n",
    "\n",
    "On souhaite d√©sormais construire une fonction `hydrate_database` qui, √† partir d'un fichier texte contenant une liste d'ID de tweets, cr√©er un fichier csv contenant les informations que l'on souhaite extraire. \n",
    "\n",
    "Due √† la limitation de requ√™te, la fonction `show_status` vue plus haut s'av√®re peu efficace pour cette t√¢che : √† raison de 900 requ√™tes pour 15 minutes, il sera beaucoup trop long de construire une base de donn√©es un tant soit peu cons√©quente. La fonction `lookup_status` (voir documentation) sera donc plus adapt√©e. Elle permettra d'hydrater 100 tweets par requ√™te, ce qui, a raison d'une limite de 900 requ√™tes pour 15 minutes, rends la construction de la base de donn√©es plus r√©aliste. Il faudra tout de m√™me g√©rer l'erreur g√©n√©rer par la limitation, si l'on souhaite avoir plus de 90000 tweets ou si l'on appelle plusieurs fois la fonction en moins de 15 minutes.\n",
    "\n",
    "#### Question 2. Impl√©menter la fonction `hydrate_database` (3.5 Pts)\n",
    "\n",
    "*Attention : Il faut √©galement g√©rer le cas o√π la feature demand√©e n'est pas une cl√© du dictionnaire mais une \"sous-cl√©\", comme c'est le cas pour le nom d'utilisateur par exemple (accessible dans la feature *user*, qui lui m√™me est un dictionnaire). Un moyen simple pour pallier √† ce probl√®me consiste √† consid√©rer la feature comme une liste, qui contiendrait la cl√© et les sous-cl√©s si il y a lieu (voir exemple plus bas)\n",
    "\n",
    "*Indice : La fonction `sleep` du module time permet de patienter le temps n√©cessaire*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hydrate_database(filename, database_name, \n",
    "                     features, nb_requests, \n",
    "                     tweet_hydratation_limit=100):\n",
    "    \"\"\"\n",
    "    Create a csv file that contains features of tweets from an file that contains ID of tweets.\n",
    "    \n",
    "    filename: Name of the file that contains ids\n",
    "    database_name: name of the file that will be created\n",
    "    features: List of features\n",
    "    nb_requests: number of time the function lookup_status will be called\n",
    "    tweet_hydratation_limit:\n",
    "    \"\"\"\n",
    "    from itertools import islice\n",
    "    from time import sleep\n",
    "    \n",
    "    # Opening the ID File:\n",
    "    file = open(filename, \"r\")\n",
    "\n",
    "    # Creation of the file that will contain the hydrated tweets:\n",
    "    with open(database_name, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "            \n",
    "            # TODO\n",
    "            n = 1\n",
    "            while n <= nb_requests :\n",
    "                OneHandredIds = [x.strip() for x in islice(file, tweet_hydratation_limit)]\n",
    "                lookupstatus = twitter.lookup_status(id=OneHandredIds)\n",
    "                for tweet in lookupstatus:\n",
    "                    csvfile.write(tweet['text']+','+tweet['user']['screen_name'])\n",
    "                    csvfile.write('\\n')\n",
    "                    #sleep(1)\n",
    "                n += 1\n",
    "\n",
    "            try: # If you don't reach the limit of requests\n",
    "\n",
    "                # TODO\n",
    "                pass\n",
    "            \n",
    "            except TwythonError as e:\n",
    "                if isinstance(e, TwythonRateLimitError):\n",
    "                    retry_after = int(e.retry_after)\n",
    "                    \n",
    "                    # TODO\n",
    "                    \n",
    "    csvfile.close()\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez le fichier suivant en guise d'example : \n",
    "https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/5QCCUU/QPYP8G&version=1.1\n",
    "\n",
    "On suppose qu'on ne souhaite garder que le texte (*text*) l'ID de l'utilisateur (*user/screen_name*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "TwythonRateLimitError",
     "evalue": "Twitter API returned a 429 (Too Many Requests), Rate limit exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTwythonRateLimitError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-a36a7c018c19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnb_requests\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhydrate_database\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_requests\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_hydratation_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-177-74aeb7bac837>\u001b[0m in \u001b[0;36mhydrate_database\u001b[1;34m(filename, database_name, features, nb_requests, tweet_hydratation_limit)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mnb_requests\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mOneHandredIds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_hydratation_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mlookupstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOneHandredIds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlookupstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                     \u001b[0mcsvfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'screen_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\twython\\endpoints.py\u001b[0m in \u001b[0;36mlookup_status\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \"\"\"\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'statuses/lookup'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdestroy_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\twython\\api.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, endpoint, params, version)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'1.1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;34m\"\"\"Shortcut for POST requests via :class:`request`\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_lastfunction_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_return_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\twython\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, endpoint, method, params, version)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         content = self._request(url, method=method, params=params,\n\u001b[1;32m--> 264\u001b[1;33m                                 api_call=url)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\twython\\api.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, url, method, params, api_call)\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0merror_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 retry_after=response.headers.get('X-Rate-Limit-Reset'))\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTwythonRateLimitError\u001b[0m: Twitter API returned a 429 (Too Many Requests), Rate limit exceeded"
     ]
    }
   ],
   "source": [
    "filename = \"climate_id.txt.00\"\n",
    "database_name = \"climate.csv\"\n",
    "features = [['text'], ['user', 'screen_name']]\n",
    "nb_requests = 400\n",
    "\n",
    "hydrate_database(filename, database_name, features, nb_requests, tweet_hydratation_limit=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/ Analyse d'une base de donn√©es au choix (16 pts)\n",
    "\n",
    "Maintenant que vous √™tes en mesure d'hydrater une base de donn√©es de tweets efficacement et en prenant en compte les limitations de Twitter, vous pouvez l'appliquer sur le *dataset* qui vous int√©resse le plus.\n",
    "\n",
    "### 1. Instructions\n",
    "\n",
    "Dans cette partie, vous allez mener **enti√®rement** de vous-m√™me un projet de *Data Science*, c'est √† dire de la collecte des donn√©es jusqu'√† l'interpr√©tation des r√©sultats. 3 sujets sont propos√©s, vous devez choisir celui qui vous int√©resse le plus parmi :\n",
    " \n",
    " 1. Analyse de sentiments pour la pr√©diction des r√©sultats de l'√©lection am√©ricaine. \n",
    "    \n",
    "    **Dataset :** \"2016 United States Presidential Election Tweet Ids\", https://doi.org/10.7910/DVN/PDI7IN  \n",
    "    \n",
    "    **Pr√©cision :** Ce sujet est assez similaire au TP1 (avec ici sentiment = parti politique), vous √™tes donc libre de reprendre ce que vous aviez fait. Cependant, il faudrait aller un peu plus en profondeur ici, par exemple sur l'√©tape de la classification. De plus, vous avez ici une nouvelle probl√©matique qui est que vos donn√©es ne sont pas labellis√©s (mais la construction des collections devrait vous permettre de labelliser vous-m√™me).\n",
    " \n",
    " \n",
    " 2. D√©tection de discours d'incitation √† la haine.\n",
    "    \n",
    "    **Dataset :** Modifier votre fonction d'hydratation en utilisant la fonction search pour n'avoir que des tweets r√©cents.\n",
    " \n",
    "     **Pr√©cision :** Ce sujet pourrait √©galement √™tre abord√© de la m√™me mani√®re que le TP1 : des √©tapes de preprocessing + de la classification. N√©anmoins, dans ce cas, poss√©der des donn√©es avec des labels \"incitant √† la haine\"/\"n'insite pas √† la haine\" est beaucoup plus complexe, car beaucoup de bases de donn√©es √©tiquet√©s, lors de l'hydratation, se trouveront √™tre quasi-vide, car les tweets auront √©t√© supprim√©s au moment o√π nous ferons notre requ√™te (car Twitter veille aussi √† la suppression de tweets haineux). C'est pourquoi vous √™tes oblig√©s de cr√©er une base de donn√©es avec des tweets les plus r√©cents possibles, avant qu'ils ne soient potentiellement supprim√©s. Pour d√©signer un tweet comme haineux, une m√©thode serait la d√©tection de vocabulaire haineux, par exemple avec `hatebase.org`, qui propose des larges bases de donn√©es tr√®s compl√®tes. Vous pouvez cr√©er un compte sur le site pour avoir acc√®s √† l'API, et ensuite utiliser cette librairie pour Python : https://github.com/DanielJDufour/hatebase. En modifiant la requ√™te pour n'avoir que des tweets contenant ce vocabulaire, et en le m√™lant √† de l'analyse de sentiment, vous pourrez obtenir des r√©sultats √† analyser. Vous pourriez aussi avoir une approche \"utilisateur\" pour rechercher des tweets haineux : lorsqu'un tweet est d√©tecter comme haineux, inspecter l'ensemble des tweets de l'utilisateur et/ou de ses *followers*. En bref, beaucoup de possibilit√©s, mais ce sujet est le plus complexe des trois. Je serai donc moins exigeant sur les r√©sultats 'chiffr√©s', l'important ici √©tant plus l'analyse, et le fait d'avoir une approche coh√©rente (il est √©galement tr√®s important de prendre le temps de r√©fl√©chir √† une d√©finition claire de \"haineux\").\n",
    "\n",
    "\n",
    " 3. M√©thodes de clusterings appliqu√© au tweet sur l'actualit√©, et analyse des r√©sultats. \n",
    "    \n",
    "    **Dataset :** \"News Outlet Tweet Ids\", https://doi.org/10.7910/DVN/2FIFLH\n",
    "\n",
    "    **Pr√©cision :** Application de m√©thodes de preprocessing, puis de m√©thodes de clustering pour regrouper les tweets qui mentionnent la m√™me actualit√© ou cat√©gorie d'actualit√© (au choix!), puis visualisation, √©tude en fonction du temps...  Vous devrez trouver quelle est la meilleur m√©thode de clustering, et celle-ci d√©pendra de votre approche (nombre de classes connu ? si oui, combien de classes?). \n",
    "    \n",
    "    \n",
    "Vous √™tes enti√®rement libre sur l'ensemble du processus (choix des informations extraites, m√©thodes en ML, librairie, etc.). Ici seul les bases de donn√©es en elle-m√™me sont rigoureusement impos√©s. Les pr√©cisions faites ici servent juste pour vous guider un peu si vous le souhaitez, mais si vous avez d'autres id√©es n'h√©sitez pas ! Ces sujets √©tant populaires au sein de la communaut√© scientifique, vous pouvez (**seulement si vous le souhaitez**) vous inspirer d'articles de la litt√©rature, √† condition de le citer dans votre rapport et de faire votre propre impl√©mentation. \n",
    "\n",
    "#### L'objectif cependant ici n'est pas d'obtenir l'√©tat de l'art, mais d'appliquer une m√©thodologie claire et rigoureuse que vous aurez construite vous-m√™me. \n",
    "\n",
    "Les datasets √©tant massifs, il est fortement d√©conseill√© de faire une base de donn√©es contenant tous les tweets hydrat√©s (par exemple, les auteurs de la BDD n¬∞1 soulignent qu'avec les limitations de l'API cela vous prendrait environ 32 jours). C'est √† vous de voir quelle est la taille du dataset dont vous avez besoin.\n",
    "\n",
    "Pensez aussi √† lire le fichier README correspondant √† la base que vous avez choisi, afin de vous aider √† mieux comprendre vos futurs r√©sultats.\n",
    "\n",
    "### 2. R√©daction d'un rapport\n",
    "\n",
    "Pour ce TP, vous allez devoir fournir un rapport qui d√©tail et justifie l'ensemble de votre m√©thode, et qui fournisse les r√©sultats que vous avez obtenus. Les √©l√©ments suivants doivent y apparaitre (cela peut vous servir de plan, mais ce n'est pas rigide) :\n",
    "\n",
    "- Titre du projet, et nom de l'ensemble des membres de l'√©quipe (avec mail et matricule)\n",
    "    \n",
    "- **Introduction** : r√©sum√© du probl√®me, de la m√©thodologie et des r√©sultats obtenus.\n",
    "\n",
    "- **Pr√©sentation du dataset** : description, justification de la taille, du choix des features, etc. \n",
    "\n",
    "- **Preprocessing** : s'il y en a, justification des √©tapes de preprocessing.\n",
    "\n",
    "- **Methodologie** : description et justification de l'ensemble des choix (algorithmes, hyper-param√®tres, r√©gularisation, m√©triques, etc.)\n",
    "\n",
    "- **R√©sultats** : analyse des r√©sultats obtenus (utilisez des figures pour illustrer), mise en relation entre les choix de design et la performance obtenue.\n",
    "\n",
    "- **Discussion** : discutez des avantages et des inconv√©nients de votre approche; quels sont les faiblesses, les failles ? Qu'est-ce qu'il peut √™tre am√©lior√© ? Vous pouvez √©galement sugg√©rer des futures id√©es d'exploration.\n",
    "\n",
    "- **R√©f√©rences** : si vous vous √™tes inspir√© d'une √©tude d√©j√† faite.\n",
    "    \n",
    "Vous pouvez utiliser le template d'arXiv pour le rapport : https://fr.overleaf.com/latex/templates/style-and-template-for-preprints-arxiv-bio-arxiv/fxsnsrzpnvwc. **L'ensemble du rapport ne doit cependant pas exc√©der 5 pages, figures et r√©f√©rences compris.** Les 5 pages ne sont pas obligatoires, si vous estimez que moins est suffisant et que votre rapport est effectivement complet, vous ne serez pas p√©nalis√©.\n",
    "\n",
    "\n",
    "### 3. Rendu attendu\n",
    "\n",
    "A la fin du TP, vous soumettrez un fichier *zip* contenant les √©l√©ments suivants:\n",
    "\n",
    "- Le fichier *pdf* du rapport\n",
    "- Ce notebook que vous aurez compl√©t√©. Vous pouvez √©galement impl√©menter votre m√©thode √† la suite ici, ou alors utiliser un autre fichier si vous le souhaitez. Bien que seul le rapport servira pour la notation, ayez un code comment√© et clair !\n",
    "- Ne pas envoyer les fichiers de donn√©es, car trop cons√©quent. Avec le rapport et le code, tout sera d√©taill√© et il sera possible de les refaire facilement.\n",
    "\n",
    "### 4. Evalutation\n",
    "\n",
    "12 points de cette partie sera bas√© sur la m√©thodologie, et 4 points sur les r√©sultats.\n",
    "\n",
    "La notation sur la m√©thodologie inclus : \n",
    "\n",
    "- La pertinence de l'ensemble des √©tapes de l'approche\n",
    "\n",
    "- La bonne description des algorithmes choisis\n",
    "\n",
    "- La justification judicieuse des choix √©tablis\n",
    "\n",
    "- Une analyse pertinente des r√©sultats\n",
    "\n",
    "- La clart√© et l'organisation du rapport (figures, tables) et du code.\n",
    "\n",
    "\n",
    "Pour ce qui est des r√©sultats, il est impossible de mettre un bar√®me fixe car ils vont d√©pendre du sujet que vous allez choisir. C'est un probl√®me auquel vous serez confront√©s : chaque √©tude √©tant sp√©cifique, il peut √™tre compliqu√© d'√©valuer qualitativement un mod√®le, d'autant que vous n'avez sans doute pas connaissance de l'√©tat de l'art. C'est pourquoi il va √™tre important de faire plusieurs essais, et de comparer diff√©rentes m√©thodes. Ainsi, les r√©sultats doivent √™tre coh√©rent avec la complexit√© de votre impl√©mentation : un mod√®le simple et na√Øf vous fournira des premiers r√©sultats, que vous devrez ensuite am√©liorer avec des mod√®les plus pr√©cis et complexes.\n",
    "\n",
    "De ce fait, l'ensemble des points pour les r√©sultats seront donn√©s si : \n",
    " - Vous obtenez des premiers r√©sultats avec une m√©thode na√Øve qui t√©moignent de la pertinence de vos choix \n",
    " - Ces r√©sultats sont ensuite am√©lior√©s avec une m√©thode plus complexe\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
